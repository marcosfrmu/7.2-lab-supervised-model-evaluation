{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfran\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (404, 13) (404, 1)\n",
      "Test set: (102, 13) (102, 1)\n"
     ]
    }
   ],
   "source": [
    "data.columns\n",
    "X= data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "       'PTRATIO', 'B', 'LSTAT']]\n",
    "Y= data.MEDV\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR= LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.07495986],\n",
       "       [26.9894969 ],\n",
       "       [17.58803353],\n",
       "       [18.15584511],\n",
       "       [36.92091659],\n",
       "       [25.43267386],\n",
       "       [31.09256932],\n",
       "       [19.72549907],\n",
       "       [19.66103377],\n",
       "       [22.96358632],\n",
       "       [28.38841214],\n",
       "       [28.48925986],\n",
       "       [18.99690357],\n",
       "       [32.41097504],\n",
       "       [21.52350275],\n",
       "       [15.25945122],\n",
       "       [21.23364112],\n",
       "       [11.6220597 ],\n",
       "       [11.37109662],\n",
       "       [13.63515584],\n",
       "       [ 5.62431971],\n",
       "       [17.35323315],\n",
       "       [20.80951594],\n",
       "       [22.51311312],\n",
       "       [16.39055556],\n",
       "       [20.32352451],\n",
       "       [17.88994185],\n",
       "       [14.23445109],\n",
       "       [21.1187098 ],\n",
       "       [17.50765806],\n",
       "       [14.54295525],\n",
       "       [23.63289896],\n",
       "       [34.32419647],\n",
       "       [22.23027161],\n",
       "       [16.82396516],\n",
       "       [20.16274383],\n",
       "       [30.67665825],\n",
       "       [35.61882904],\n",
       "       [23.50372003],\n",
       "       [24.66451121],\n",
       "       [36.91269871],\n",
       "       [32.33290254],\n",
       "       [19.11785719],\n",
       "       [32.19546605],\n",
       "       [33.42795148],\n",
       "       [25.52705821],\n",
       "       [40.63477427],\n",
       "       [18.21762788],\n",
       "       [19.34587461],\n",
       "       [23.80167377],\n",
       "       [33.42122982],\n",
       "       [26.1451108 ],\n",
       "       [18.10363121],\n",
       "       [28.19906437],\n",
       "       [13.37486655],\n",
       "       [23.34019279],\n",
       "       [24.44952678],\n",
       "       [33.54973856],\n",
       "       [16.71263275],\n",
       "       [36.56402224],\n",
       "       [15.69684554],\n",
       "       [18.55447039],\n",
       "       [32.14543203],\n",
       "       [15.49568061],\n",
       "       [39.02363234],\n",
       "       [27.38174402],\n",
       "       [31.96333419],\n",
       "       [10.09436162],\n",
       "       [19.13214621],\n",
       "       [21.73038157],\n",
       "       [23.14682001],\n",
       "       [22.82615401],\n",
       "       [22.51245566],\n",
       "       [28.21477189],\n",
       "       [17.13262484],\n",
       "       [23.08039019],\n",
       "       [16.65978367],\n",
       "       [25.17892617],\n",
       "       [13.68806399],\n",
       "       [19.8195139 ],\n",
       "       [22.31237842],\n",
       "       [20.24637447],\n",
       "       [28.35989119],\n",
       "       [19.12635952],\n",
       "       [30.49206633],\n",
       "       [22.25649076],\n",
       "       [29.98229473],\n",
       "       [19.27750127],\n",
       "       [23.73890345],\n",
       "       [38.32216452],\n",
       "       [31.24781499],\n",
       "       [41.92137782],\n",
       "       [18.61466511],\n",
       "       [37.47526878],\n",
       "       [19.66151941],\n",
       "       [23.44504636],\n",
       "       [26.55358092],\n",
       "       [22.38454399],\n",
       "       [ 9.59394823],\n",
       "       [20.39499251],\n",
       "       [ 9.22793989],\n",
       "       [27.36219976]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(X_train, y_train)\n",
    "LR_pre= LR.predict(X_test)\n",
    "LR_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7263451459702515"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,LR_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.4195871268218"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set= X_train, y_train\n",
    "test_set= X_test, y_test\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, LR_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.36779098379658"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, LR_pre )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "X= data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)']]\n",
    "Y= data['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfran\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogR= LogisticRegression( max_iter= 2000, solver='liblinear')\n",
    "LogR.fit(X_train, y_train)\n",
    "LogR_pre= LogR.predict(X_test)\n",
    "LogR_pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, LogR_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962962962962964"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, LogR_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, LogR_pre, average= 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, LogR_pre, average= 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "128      2\n",
       "18       0\n",
       "130      2\n",
       "105      2\n",
       "107      2\n",
       "78       1\n",
       "83       1\n",
       "14       0\n",
       "5        0\n",
       "133      2\n",
       "25       0\n",
       "11       0\n",
       "12       0\n",
       "63       1\n",
       "113      2\n",
       "34       0\n",
       "60       1\n",
       "2        0\n",
       "24       0\n",
       "123      2\n",
       "35       0\n",
       "124      2\n",
       "68       1\n",
       "26       0\n",
       "29       0\n",
       "19       0\n",
       "41       0\n",
       "16       0\n",
       "20       0\n",
       "101      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, LogR_pre, average= 'micro')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0,  4,  1],\n",
       "       [ 0,  1,  8]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, LogR_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[16  0  0]\n",
      " [ 0  4  1]\n",
      " [ 0  1  8]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cnf_matrix = confusion_matrix(y_test, LogR_pre, labels=[0,1, 2])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['class=0','class=1', 'class=2'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
